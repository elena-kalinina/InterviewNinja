# InterviewNinja ðŸ¥·

A voice-powered ML/AI interview preparation platform. Practice technical interviews with an AI interviewer that speaks, listens, and provides feedback.

## Features

- **4 Interview Types**:
  - ðŸ§  **System Design** - Draw diagrams on an interactive canvas while discussing ML system architecture
  - ðŸ’» **Live Coding** - Write and execute code in a Monaco editor (Python, JavaScript, Java, etc.)
  - ðŸ“š **ML Theory** - Discuss theoretical concepts with LaTeX formula rendering
  - ðŸ’¬ **Coaching** - General interview prep and career coaching

- **Voice Interaction**:
  - AI interviewer speaks using Eleven Labs TTS (female voice)
  - Speech-to-text for your responses
  - Natural conversation flow

- **Customization**:
  - **Verbosity**: Low / Medium / High
  - **Tone**: Friendly / Neutral / Adversarial
  - **Problem Source**: Random / Custom Description / URL Scraping

- **Session Management**:
  - Save interview transcripts
  - AI-powered session analysis with scores and feedback

## Tech Stack

| Layer | Technology |
|-------|------------|
| Frontend | React 18, Vite, TailwindCSS |
| Canvas | Fabric.js |
| Code Editor | Monaco Editor |
| Formula Rendering | KaTeX |
| Backend | FastAPI (Python) |
| Voice TTS | Eleven Labs API |
| Voice STT | Web Speech API |
| LLM | OpenAI GPT-4 |
| Code Execution | Piston API |

## Prerequisites

- Node.js 18+
- Python 3.11+
- OpenAI API key
- Eleven Labs API key

## Setup

### 1. Clone and Configure Environment

```bash
cd InterviewNinja

# Create .env file with your API keys
cat > .env << EOF
OPENAI_API_KEY=your_openai_api_key_here
ELEVENLABS_API_KEY=your_elevenlabs_api_key_here
EOF
```

### 2. Backend Setup

```bash
# Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r backend/requirements.txt

# Run the server
cd backend
uvicorn app.main:app --reload --port 8000
```

### 3. Frontend Setup

```bash
cd frontend

# Install dependencies
npm install

# Start development server
npm run dev
```

### 4. Access the Application

- Frontend: http://localhost:5173
- Backend API: http://localhost:8000
- API Docs: http://localhost:8000/docs

## Usage

1. **Select Interview Type** - Choose from the tabs at the top
2. **Configure Settings** - Set verbosity, tone, and problem source in the sidebar
3. **Start Interview** - Click the "Start Interview" button
4. **Interact** - Use the microphone button to speak or type in the chat
5. **Analyze** - Click "Analyze" to get AI feedback on your performance

## Project Structure

```
InterviewNinja/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ main.py              # FastAPI app entry point
â”‚   â”‚   â”œâ”€â”€ routers/
â”‚   â”‚   â”‚   â”œâ”€â”€ voice.py         # Voice/interview endpoints
â”‚   â”‚   â”‚   â”œâ”€â”€ session.py       # Session management
â”‚   â”‚   â”‚   â”œâ”€â”€ scraper.py       # URL scraping
â”‚   â”‚   â”‚   â””â”€â”€ code_execution.py # Code runner
â”‚   â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”‚   â”œâ”€â”€ openai_service.py    # GPT-4 integration
â”‚   â”‚   â”‚   â”œâ”€â”€ elevenlabs_service.py # TTS
â”‚   â”‚   â”‚   â””â”€â”€ problem_bank.py      # Sample problems
â”‚   â”‚   â””â”€â”€ models/
â”‚   â”‚       â””â”€â”€ schemas.py       # Pydantic models
â”‚   â””â”€â”€ requirements.txt
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ App.jsx              # Main app component
â”‚   â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”‚   â”œâ”€â”€ tabs/            # Interview type tabs
â”‚   â”‚   â”‚   â”œâ”€â”€ controls/        # Voice and settings controls
â”‚   â”‚   â”‚   â”œâ”€â”€ canvas/          # Drawing canvas
â”‚   â”‚   â”‚   â””â”€â”€ shared/          # Reusable components
â”‚   â”‚   â”œâ”€â”€ hooks/
â”‚   â”‚   â”‚   â”œâ”€â”€ useVoiceAgent.js # Voice interaction hook
â”‚   â”‚   â”‚   â””â”€â”€ useSession.js    # Session management hook
â”‚   â”‚   â””â”€â”€ services/
â”‚   â”‚       â””â”€â”€ api.js           # Backend API client
â”‚   â”œâ”€â”€ index.html
â”‚   â””â”€â”€ package.json
â”œâ”€â”€ .env                         # API keys (not in git)
â””â”€â”€ README.md
```

## API Endpoints

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/api/voice/start` | POST | Start new interview session |
| `/api/voice/respond` | POST | Send user message, get AI response |
| `/api/voice/tts` | POST | Text-to-speech conversion |
| `/api/session/save` | POST | Save session transcript |
| `/api/session/analyze` | POST | Get AI analysis of session |
| `/api/scraper/extract` | POST | Extract problems from URL |
| `/api/code/execute` | POST | Execute code via Piston |

## Voice Selection

The platform uses Eleven Labs for text-to-speech. The default voice is configured to be a warm female voice. You can customize this in `backend/app/services/elevenlabs_service.py`.

## Troubleshooting

### Microphone not working
- Ensure your browser has microphone permissions
- Check that no other application is using the microphone
- Try using Chrome for best Web Speech API support

### Code execution fails
- The Piston API is a free service with rate limits
- For production, consider self-hosting Piston or using Pyodide for Python

### Audio not playing
- Check browser autoplay settings
- Ensure Eleven Labs API key is valid and has credits

## License

MIT
